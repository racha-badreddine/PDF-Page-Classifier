{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9wcf3w1o6ld"
      },
      "source": [
        "# **DataSet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrDs0NUZPmsM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('SONDATA.csv')\n",
        "\n",
        "# Preprocess Data\n",
        "data.isnull().sum()\n",
        "data['Text'].fillna('', inplace=True)\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "data['Label'] = label_encoder.fit_transform(data['Label'])\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = Tokenizer(num_words=5000, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(data['Text'])\n",
        "sequences = tokenizer.texts_to_sequences(data['Text'])\n",
        "padded_sequences = pad_sequences(sequences, maxlen=200, padding='post', truncating='post')\n",
        "\n",
        "# Data Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, data['Label'], test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5UYJWqSpB_J"
      },
      "source": [
        "# **Training The Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ivP-KRoQhbN",
        "outputId": "2c81b8dc-cf40-4f81-ff18-daf7e73ca377"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.regularizers import L2\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "\n",
        "# Model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=5000, output_dim=128, input_length=200),\n",
        "    LSTM(128, return_sequences=True),\n",
        "    Dropout(0.5),\n",
        "    LSTM(128),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu', kernel_regularizer=L2(0.01)),\n",
        "    Dropout(0.5),\n",
        "    Dense(32, activation='relu', kernel_regularizer=L2(0.01)),\n",
        "    Dense(16, activation='relu', kernel_regularizer=L2(0.01)),\n",
        "    Dense(1, activation='linear', kernel_regularizer=L2(0.01))\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(loss=BinaryCrossentropy(from_logits=True), optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGxbKbjQQk_K",
        "outputId": "8be6af93-e8a2-4576-f6bf-8f2773fe8d91"
      },
      "outputs": [],
      "source": [
        "\n",
        "history = model.fit(X_train, y_train, epochs=16, batch_size=8, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zK_eYikJQnCc",
        "outputId": "69a875f7-3cba-47a3-cb54-1f0a410b43a2"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Evaluation\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy:.2f}')\n",
        "\n",
        "# Apply Sigmoid Function to the Logits\n",
        "y_pred = (tf.nn.sigmoid(model.predict(X_test)).numpy() > 0.5).astype(int)\n",
        "\n",
        "\n",
        "# Classification report\n",
        "y_test_labels = label_encoder.inverse_transform(y_test)\n",
        "y_pred_labels = label_encoder.inverse_transform(y_pred.flatten())\n",
        "\n",
        "target_names = [str(cls) for cls in label_encoder.classes_]\n",
        "\n",
        "print(classification_report(y_test_labels, y_pred_labels, target_names=target_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bSOGHxZowdl"
      },
      "source": [
        "# **Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDa6brEs5NQY"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "# Save the model to a file using joblib\n",
        "filename = 'your_model.joblib'\n",
        "joblib.dump(model, filename)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# Assuming model is the trained Keras model\n",
        "model.save('model2.keras')\n",
        "\n",
        "# Save the tokenizer\n",
        "import pickle\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# Save the label encoder\n",
        "with open('label_encoder.pickle', 'wb') as handle:\n",
        "    pickle.dump(label_encoder, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
